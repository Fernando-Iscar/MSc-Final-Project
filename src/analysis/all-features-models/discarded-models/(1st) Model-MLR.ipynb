{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIPLE LINEAR REGRESSION - MLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL: \n",
    "\n",
    "- “Country”, “Jobtype”, “Education”, “Job title”, “Company size”, “Age”, “Experience” and “Annual Salary” \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Company_size</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_type_Full-time employed</th>\n",
       "      <th>Job_type_Independent contractor / Freelancer / Self-employed</th>\n",
       "      <th>Job_type_Other</th>\n",
       "      <th>Job_type_Part-time employed</th>\n",
       "      <th>Country_Andorra</th>\n",
       "      <th>Country_Angola</th>\n",
       "      <th>Country_Argentina</th>\n",
       "      <th>...</th>\n",
       "      <th>Marketing or sales professional</th>\n",
       "      <th>Product manager</th>\n",
       "      <th>Project manager</th>\n",
       "      <th>Scientist</th>\n",
       "      <th>Security professional</th>\n",
       "      <th>Senior Executive (C-Suite, VP, etc.)</th>\n",
       "      <th>Student</th>\n",
       "      <th>System administrator</th>\n",
       "      <th>Work_experience</th>\n",
       "      <th>Annual_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>40205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>52769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>72243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>62820.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  Company_size  Age  Job_type_Full-time employed  \\\n",
       "0        2.0           1.0  3.0                          1.0   \n",
       "1        3.0           1.0  3.0                          1.0   \n",
       "2        2.0           1.0  3.0                          1.0   \n",
       "3        2.0           2.0  3.0                          1.0   \n",
       "4        0.0           3.0  3.0                          1.0   \n",
       "\n",
       "   Job_type_Independent contractor / Freelancer / Self-employed  \\\n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                0.0              \n",
       "3                                                0.0              \n",
       "4                                                0.0              \n",
       "\n",
       "   Job_type_Other  Job_type_Part-time employed  Country_Andorra  \\\n",
       "0             0.0                          0.0              0.0   \n",
       "1             0.0                          0.0              0.0   \n",
       "2             0.0                          0.0              0.0   \n",
       "3             0.0                          0.0              0.0   \n",
       "4             0.0                          0.0              0.0   \n",
       "\n",
       "   Country_Angola  Country_Argentina  ...  Marketing or sales professional  \\\n",
       "0             0.0                0.0  ...                                0   \n",
       "1             0.0                0.0  ...                                0   \n",
       "2             0.0                0.0  ...                                0   \n",
       "3             0.0                0.0  ...                                0   \n",
       "4             0.0                0.0  ...                                0   \n",
       "\n",
       "   Product manager  Project manager  Scientist  Security professional  \\\n",
       "0                0                0          0                      0   \n",
       "1                0                0          1                      0   \n",
       "2                0                0          0                      0   \n",
       "3                0                0          0                      0   \n",
       "4                0                0          0                      0   \n",
       "\n",
       "   Senior Executive (C-Suite, VP, etc.)  Student  System administrator  \\\n",
       "0                                     0        0                     0   \n",
       "1                                     0        0                     0   \n",
       "2                                     0        0                     0   \n",
       "3                                     0        0                     0   \n",
       "4                                     0        0                     1   \n",
       "\n",
       "   Work_experience  Annual_salary  \n",
       "0              4.8        40205.0  \n",
       "1              6.4        52769.0  \n",
       "2              6.0        54025.0  \n",
       "3              7.8        72243.0  \n",
       "4             11.4        62820.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_and_encoded_df.csv')\n",
    "\n",
    "baseline_cols = [\"Country\", \"Job_type\", \"Education\", \"Company_size\", \"Age\", \"Work_experience\", \"Annual_salary\"]\n",
    "\n",
    "# Add Job_title columns to the baseline_cols list\n",
    "Job_title = ['Developer, game or graphics', 'Blockchain', 'Developer, QA or test', 'Developer, back-end', 'Student', \n",
    "             'Project manager', 'Data or business analyst', 'Cloud infrastructure engineer', 'Engineer, data', \n",
    "             'Educator', 'Developer, desktop or enterprise applications', 'Developer, front-end', 'Designer', \n",
    "             'Security professional', 'Developer, embedded applications or devices', 'Product manager', 'Developer, mobile', \n",
    "             'Developer, full-stack', 'Scientist', 'Database administrator', 'Academic researcher', 'Senior Executive (C-Suite, VP, etc.)', \n",
    "             'Marketing or sales professional', 'System administrator', 'Data scientist or machine learning specialist', \n",
    "             'Engineer, site reliability', 'DevOps specialist', 'Engineering manager']\n",
    "\n",
    "baseline_cols.extend(Job_title)\n",
    "\n",
    "# Iterate through the columns and keep only those containing the specified keywords\n",
    "columns_to_keep = [col for col in df.columns if any(keyword in col for keyword in baseline_cols)]\n",
    "\n",
    "# Filter the DataFrame, keeping only the selected columns\n",
    "baseline_df = df[columns_to_keep]\n",
    "\n",
    "\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2805, 138)\n",
      "(2805,)\n"
     ]
    }
   ],
   "source": [
    "base_X = baseline_df.drop('Annual_salary', axis=1)\n",
    "y = baseline_df['Annual_salary']\n",
    "print(base_X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(base_X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n",
      "processing fold # 4\n",
      "Average R2 score (MLR): -13449265799566006140249571328.000 (+/- 8162682659846925347907960832.000)\n",
      "Average adjusted R2 score (MLR): -19455734020731410271308873728.000 (+/- 11808152585603807084718063616.000)\n",
      "Average RMSE score (MLR): 5627748511452433408.000 (+/- 1790368162893868544.000)\n",
      "Average MAE score (MLR): 506460911501264576.000 (+/- 130522419233085856.000)\n"
     ]
    }
   ],
   "source": [
    "# Code with Adj R2\n",
    "\n",
    "k = 5\n",
    "num_val_samples = len(X_train_scaled) // k\n",
    "all_scores_r2_mlr = []\n",
    "all_scores_rmse_mlr = []\n",
    "all_scores_mae_mlr = []\n",
    "all_scores_adj_r2_mlr = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = X_train_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X_train_scaled[:i * num_val_samples],\n",
    "         X_train_scaled[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y_train[:i * num_val_samples],\n",
    "         y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(partial_train_data, partial_train_targets)\n",
    "\n",
    "    val_preds = model.predict(val_data)\n",
    "    r2_val = r2_score(val_targets, val_preds)\n",
    "    rmse_val = np.sqrt(mean_squared_error(val_targets, val_preds))\n",
    "    mae_val = mean_absolute_error(val_targets, val_preds)\n",
    "\n",
    "    n = len(val_data)\n",
    "    p = partial_train_data.shape[1]\n",
    "    adjusted_r2_val = 1 - (1 - r2_val) * (n - 1) / (n - p - 1)\n",
    "    all_scores_adj_r2_mlr.append(adjusted_r2_val)\n",
    "\n",
    "    all_scores_r2_mlr.append(r2_val)\n",
    "    all_scores_rmse_mlr.append(rmse_val)\n",
    "    all_scores_mae_mlr.append(mae_val)\n",
    "\n",
    "mean_r2_mlr = np.mean(all_scores_r2_mlr)\n",
    "std_r2_mlr = np.std(all_scores_r2_mlr)\n",
    "mean_rmse_mlr = np.mean(all_scores_rmse_mlr)\n",
    "std_rmse_mlr = np.std(all_scores_rmse_mlr)\n",
    "mean_mae_mlr = np.mean(all_scores_mae_mlr)\n",
    "std_mae_mlr = np.std(all_scores_mae_mlr)\n",
    "\n",
    "mean_adj_r2_mlr = np.mean(all_scores_adj_r2_mlr)\n",
    "std_adj_r2_mlr = np.std(all_scores_adj_r2_mlr)\n",
    "\n",
    "print(f\"Average R2 score (MLR): {mean_r2_mlr:.3f} (+/- {std_r2_mlr:.3f})\")\n",
    "print(f\"Average adjusted R2 score (MLR): {mean_adj_r2_mlr:.3f} (+/- {std_adj_r2_mlr:.3f})\")\n",
    "print(f\"Average RMSE score (MLR): {mean_rmse_mlr:.3f} (+/- {std_rmse_mlr:.3f})\")\n",
    "print(f\"Average MAE score (MLR): {mean_mae_mlr:.3f} (+/- {std_mae_mlr:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>-1.344927e+28</td>\n",
       "      <td>-1.945573e+28</td>\n",
       "      <td>5.627749e+18</td>\n",
       "      <td>5.064609e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R2        Adj R2          RMSE           MAE\n",
       "MLR -1.344927e+28 -1.945573e+28  5.627749e+18  5.064609e+17"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_results_dic = {}\n",
    "\n",
    "mlr_results_dic['MLR'] = {'R2': mean_r2_mlr, 'Adj R2': mean_adj_r2_mlr, 'RMSE': mean_rmse_mlr, 'MAE': mean_mae_mlr }\n",
    "mlr_results = pd.DataFrame.from_dict(mlr_results_dic, orient='index')\n",
    "mlr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_results.to_csv('mlr_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 in validation set (MLR): -6495178786499154482823168.000\n",
      "Adjusted R2 in validation set (MLR): -8619194598197929971810304.000\n",
      "RMSE in validation set (MLR): 129230559979504848.000\n",
      "MAE  in validation set (MLR): 14076571778101968.000\n"
     ]
    }
   ],
   "source": [
    "# Combine the training and validation sets\n",
    "X_train_val = np.concatenate((X_train_scaled, val_data), axis=0)\n",
    "y_train_val = np.concatenate((y_train, val_targets), axis=0)\n",
    "\n",
    "# Train the model on the combined training and validation sets\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the R2 score, Adjusted R2, RMSE, and MAE\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "n_test = len(X_test_scaled)\n",
    "p_test = X_train_val.shape[1]\n",
    "adjusted_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "\n",
    "print(f\"R2 in validation set (MLR): {r2_test:.3f}\")\n",
    "print(f\"Adjusted R2 in validation set (MLR): {adjusted_r2_test:.3f}\")\n",
    "print(f\"RMSE in validation set (MLR): {rmse_test:.3f}\")\n",
    "print(f\"MAE  in validation set (MLR): {mae_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>-6.495179e+24</td>\n",
       "      <td>-8.619195e+24</td>\n",
       "      <td>1.292306e+17</td>\n",
       "      <td>1.407657e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R2        Adj R2          RMSE           MAE\n",
       "MLR -6.495179e+24 -8.619195e+24  1.292306e+17  1.407657e+16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_dic = {}\n",
    "test_results_dic['MLR'] = {'R2': r2_test,  'Adj R2': adjusted_r2_test, 'RMSE': rmse_test, 'MAE': mae_test}\n",
    "test_results = pd.DataFrame.from_dict(test_results_dic, orient='index')\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.to_csv('test_mlr_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 582. TiB for an array with shape (79998391433420,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fenan\\OneDrive\\Desktop\\NETHERLANDS\\MSc DATA SCIENCE 22-23\\Final Thesis\\AA - Thesis Process\\Code\\Baseline_Models\\(1st) Model-MLR.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fenan/OneDrive/Desktop/NETHERLANDS/MSc%20DATA%20SCIENCE%2022-23/Final%20Thesis/AA%20-%20Thesis%20Process/Code/Baseline_Models/%281st%29%20Model-MLR.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m g\u001b[39m.\u001b[39mplot_joint(sns\u001b[39m.\u001b[39mregplot, scatter_kws\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgrey\u001b[39m\u001b[39m'\u001b[39m}, line_kws\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpurple\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fenan/OneDrive/Desktop/NETHERLANDS/MSc%20DATA%20SCIENCE%2022-23/Final%20Thesis/AA%20-%20Thesis%20Process/Code/Baseline_Models/%281st%29%20Model-MLR.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Add histograms\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fenan/OneDrive/Desktop/NETHERLANDS/MSc%20DATA%20SCIENCE%2022-23/Final%20Thesis/AA%20-%20Thesis%20Process/Code/Baseline_Models/%281st%29%20Model-MLR.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m g\u001b[39m.\u001b[39;49mplot_marginals(sns\u001b[39m.\u001b[39;49mhistplot, kde\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgrey\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fenan/OneDrive/Desktop/NETHERLANDS/MSc%20DATA%20SCIENCE%2022-23/Final%20Thesis/AA%20-%20Thesis%20Process/Code/Baseline_Models/%281st%29%20Model-MLR.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Adjust the arrangement of the plots\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fenan/OneDrive/Desktop/NETHERLANDS/MSc%20DATA%20SCIENCE%2022-23/Final%20Thesis/AA%20-%20Thesis%20Process/Code/Baseline_Models/%281st%29%20Model-MLR.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m g\u001b[39m.\u001b[39mfig\u001b[39m.\u001b[39msubplots_adjust(top\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:1883\u001b[0m, in \u001b[0;36mJointGrid.plot_marginals\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m   1880\u001b[0m     func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39morient_kw_x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1882\u001b[0m \u001b[39mif\u001b[39;00m seaborn_func:\n\u001b[1;32m-> 1883\u001b[0m     func(y\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my, ax\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39max_marg_y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1884\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1885\u001b[0m     plt\u001b[39m.\u001b[39msca(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39max_marg_y)\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:1432\u001b[0m, in \u001b[0;36mhistplot\u001b[1;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1421\u001b[0m estimate_kws \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m   1422\u001b[0m     stat\u001b[39m=\u001b[39mstat,\n\u001b[0;32m   1423\u001b[0m     bins\u001b[39m=\u001b[39mbins,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     cumulative\u001b[39m=\u001b[39mcumulative,\n\u001b[0;32m   1428\u001b[0m )\n\u001b[0;32m   1430\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39munivariate:\n\u001b[1;32m-> 1432\u001b[0m     p\u001b[39m.\u001b[39mplot_univariate_histogram(\n\u001b[0;32m   1433\u001b[0m         multiple\u001b[39m=\u001b[39mmultiple,\n\u001b[0;32m   1434\u001b[0m         element\u001b[39m=\u001b[39melement,\n\u001b[0;32m   1435\u001b[0m         fill\u001b[39m=\u001b[39mfill,\n\u001b[0;32m   1436\u001b[0m         shrink\u001b[39m=\u001b[39mshrink,\n\u001b[0;32m   1437\u001b[0m         common_norm\u001b[39m=\u001b[39mcommon_norm,\n\u001b[0;32m   1438\u001b[0m         common_bins\u001b[39m=\u001b[39mcommon_bins,\n\u001b[0;32m   1439\u001b[0m         kde\u001b[39m=\u001b[39mkde,\n\u001b[0;32m   1440\u001b[0m         kde_kws\u001b[39m=\u001b[39mkde_kws,\n\u001b[0;32m   1441\u001b[0m         color\u001b[39m=\u001b[39mcolor,\n\u001b[0;32m   1442\u001b[0m         legend\u001b[39m=\u001b[39mlegend,\n\u001b[0;32m   1443\u001b[0m         estimate_kws\u001b[39m=\u001b[39mestimate_kws,\n\u001b[0;32m   1444\u001b[0m         line_kws\u001b[39m=\u001b[39mline_kws,\n\u001b[0;32m   1445\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1446\u001b[0m     )\n\u001b[0;32m   1448\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1450\u001b[0m     p\u001b[39m.\u001b[39mplot_bivariate_histogram(\n\u001b[0;32m   1451\u001b[0m         common_bins\u001b[39m=\u001b[39mcommon_bins,\n\u001b[0;32m   1452\u001b[0m         common_norm\u001b[39m=\u001b[39mcommon_norm,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1463\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:475\u001b[0m, in \u001b[0;36m_DistributionPlotter.plot_univariate_histogram\u001b[1;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39m# Do the histogram computation\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (multiple_histograms \u001b[39mand\u001b[39;00m common_bins):\n\u001b[1;32m--> 475\u001b[0m     bin_kws \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49m_define_bin_params(sub_data, orient, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    476\u001b[0m res \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m_normalize(estimator\u001b[39m.\u001b[39m_eval(sub_data, orient, bin_kws))\n\u001b[0;32m    477\u001b[0m heights \u001b[39m=\u001b[39m res[estimator\u001b[39m.\u001b[39mstat]\u001b[39m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\seaborn\\_stats\\counting.py:152\u001b[0m, in \u001b[0;36mHist._define_bin_params\u001b[1;34m(self, data, orient, scale_type)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39m# TODO We'll want this for ordinal / discrete scales too\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m# (Do we need discrete as a parameter or just infer from scale?)\u001b[39;00m\n\u001b[0;32m    150\u001b[0m discrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscrete \u001b[39mor\u001b[39;00m scale_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnominal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 152\u001b[0m bin_edges \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_define_bin_edges(\n\u001b[0;32m    153\u001b[0m     vals, weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbins, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinwidth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinrange, discrete,\n\u001b[0;32m    154\u001b[0m )\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbins, (\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m)):\n\u001b[0;32m    157\u001b[0m     n_bins \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(bin_edges) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\seaborn\\_stats\\counting.py:137\u001b[0m, in \u001b[0;36mHist._define_bin_edges\u001b[1;34m(self, vals, weight, bins, binwidth, binrange, discrete)\u001b[0m\n\u001b[0;32m    135\u001b[0m     bin_edges \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(start, stop \u001b[39m+\u001b[39m step, step)\n\u001b[0;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     bin_edges \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhistogram_bin_edges(vals, bins, binrange, weight)\n\u001b[0;32m    139\u001b[0m \u001b[39m# TODO warning or cap on too many bins?\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mreturn\u001b[39;00m bin_edges\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mhistogram_bin_edges\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:669\u001b[0m, in \u001b[0;36mhistogram_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39mFunction to calculate only the edges of the bins used by the `histogram`\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39mfunction.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    666\u001b[0m \n\u001b[0;32m    667\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    668\u001b[0m a, weights \u001b[39m=\u001b[39m _ravel_and_check_weights(a, weights)\n\u001b[1;32m--> 669\u001b[0m bin_edges, _ \u001b[39m=\u001b[39m _get_bin_edges(a, bins, \u001b[39mrange\u001b[39;49m, weights)\n\u001b[0;32m    670\u001b[0m \u001b[39mreturn\u001b[39;00m bin_edges\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:446\u001b[0m, in \u001b[0;36m_get_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    443\u001b[0m         bin_type \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mresult_type(bin_type, \u001b[39mfloat\u001b[39m)\n\u001b[0;32m    445\u001b[0m     \u001b[39m# bin edges must be computed\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     bin_edges \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinspace(\n\u001b[0;32m    447\u001b[0m         first_edge, last_edge, n_equal_bins \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m    448\u001b[0m         endpoint\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mbin_type)\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m bin_edges, (first_edge, last_edge, n_equal_bins)\n\u001b[0;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fenan\\anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py:135\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    132\u001b[0m     dtype \u001b[39m=\u001b[39m dt\n\u001b[0;32m    134\u001b[0m delta \u001b[39m=\u001b[39m stop \u001b[39m-\u001b[39m start\n\u001b[1;32m--> 135\u001b[0m y \u001b[39m=\u001b[39m _nx\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, num, dtype\u001b[39m=\u001b[39;49mdt)\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m ndim(delta))\n\u001b[0;32m    136\u001b[0m \u001b[39m# In-place multiplication y *= delta/div is faster, but prevents the multiplicant\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m# see gh-7142. Hence, we multiply in place only for standard scalar types.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m _mult_inplace \u001b[39m=\u001b[39m _nx\u001b[39m.\u001b[39misscalar(delta)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 582. TiB for an array with shape (79998391433420,) and data type float64"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a joint dataframe by concatenating the two variables\n",
    "g = sns.JointGrid(x=y_test, y=y_pred, height=5)\n",
    "\n",
    "# Create scatterplot and regression plots\n",
    "g.plot_joint(sns.regplot, scatter_kws={'color': 'grey'}, line_kws={'color': 'purple'})\n",
    "\n",
    "# Add histograms\n",
    "g.plot_marginals(sns.histplot, kde=False, color='grey')\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "\n",
    "# Add title \n",
    "g.fig.suptitle(\"MLR performance - Test set\")\n",
    "\n",
    "# Add labels to the plot\n",
    "g.ax_joint.set_xlabel(\"Truth\")\n",
    "g.ax_joint.set_ylabel(\"Predictions\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
